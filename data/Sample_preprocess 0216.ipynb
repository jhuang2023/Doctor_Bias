{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "import gensim\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>href</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>Ease_of_Appointment</th>\n",
       "      <th>Promptness</th>\n",
       "      <th>Courteous_Staff</th>\n",
       "      <th>Accurate_Diagnosis</th>\n",
       "      <th>Bedside_Manner</th>\n",
       "      <th>Spends_Time_with_Me</th>\n",
       "      <th>...</th>\n",
       "      <th>Advanced_Technology</th>\n",
       "      <th>Caring_Manner</th>\n",
       "      <th>Pain_Minimized</th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>crawl_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12949966</td>\n",
       "      <td>23507540</td>\n",
       "      <td>/dentists/Dr_Aarika_Anderson_Elter</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Great results</td>\n",
       "      <td>Dr. Anderson explained in detail my options fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12949967</td>\n",
       "      <td>27184431</td>\n",
       "      <td>/dentists/Dr_Aamir_Wahab</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>Brad s.</td>\n",
       "      <td>implant</td>\n",
       "      <td>Had an implant done and it was painless. I cou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12949968</td>\n",
       "      <td>26307282</td>\n",
       "      <td>/dentists/Dr_Aanal_Parikh</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-10-12</td>\n",
       "      <td>Bill johnson</td>\n",
       "      <td>Warning ..would not see this dentist</td>\n",
       "      <td>Do not go to this dentist office they scam peo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12949969</td>\n",
       "      <td>28904504</td>\n",
       "      <td>/dentists/Dr_Aaron_Aguilar</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very thoughtful Dr.  Communicates/bedside mann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12949970</td>\n",
       "      <td>28380953</td>\n",
       "      <td>/dentists/Dr_Aaron_D_Larsen</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr larsen great others no</td>\n",
       "      <td>Would continue to see Dr.  Larsen however his ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  review_id                                href  overall_rating  \\\n",
       "0  12949966   23507540  /dentists/Dr_Aarika_Anderson_Elter               5   \n",
       "1  12949967   27184431            /dentists/Dr_Aamir_Wahab               5   \n",
       "2  12949968   26307282           /dentists/Dr_Aanal_Parikh               1   \n",
       "3  12949969   28904504          /dentists/Dr_Aaron_Aguilar               5   \n",
       "4  12949970   28380953         /dentists/Dr_Aaron_D_Larsen               4   \n",
       "\n",
       "   Ease_of_Appointment  Promptness  Courteous_Staff  Accurate_Diagnosis  \\\n",
       "0                  4.0         NaN              NaN                 NaN   \n",
       "1                  5.0         NaN              NaN                 NaN   \n",
       "2                  1.0         NaN              NaN                 NaN   \n",
       "3                  5.0         NaN              NaN                 NaN   \n",
       "4                  3.0         NaN              NaN                 NaN   \n",
       "\n",
       "   Bedside_Manner  Spends_Time_with_Me         ...           \\\n",
       "0             NaN                  NaN         ...            \n",
       "1             NaN                  NaN         ...            \n",
       "2             NaN                  NaN         ...            \n",
       "3             NaN                  NaN         ...            \n",
       "4             NaN                  NaN         ...            \n",
       "\n",
       "   Advanced_Technology  Caring_Manner  Pain_Minimized  Satisfaction  \\\n",
       "0                  NaN            5.0             5.0           NaN   \n",
       "1                  5.0            5.0             5.0           5.0   \n",
       "2                  1.0            1.0             1.0           1.0   \n",
       "3                  5.0            5.0             5.0           5.0   \n",
       "4                  4.0            4.0             4.0           5.0   \n",
       "\n",
       "         date      reviewer                                 title  \\\n",
       "0  2012-11-16           NaN                        Great results    \n",
       "1  2015-03-15       Brad s.                               implant   \n",
       "2  2014-10-12  Bill johnson  Warning ..would not see this dentist   \n",
       "3  2015-06-11           NaN                                   NaN   \n",
       "4  2015-03-31           NaN             Dr larsen great others no   \n",
       "\n",
       "                                             content helpful_vote  \\\n",
       "0  Dr. Anderson explained in detail my options fo...          NaN   \n",
       "1  Had an implant done and it was painless. I cou...          NaN   \n",
       "2  Do not go to this dentist office they scam peo...          NaN   \n",
       "3  Very thoughtful Dr.  Communicates/bedside mann...          NaN   \n",
       "4  Would continue to see Dr.  Larsen however his ...          NaN   \n",
       "\n",
       "            crawl_date  \n",
       "0  2016-09-06 20:54:01  \n",
       "1  2016-09-06 20:54:10  \n",
       "2  2016-09-06 20:54:13  \n",
       "3  2016-09-06 20:54:14  \n",
       "4  2016-09-06 20:54:18  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_panel = pd.read_csv('./data/reviews_panel_t8.csv')\n",
    "review_panel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1796204, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_panel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_panel_text = review_panel['title'].fillna('').astype(str) + \" \" + review_panel['content'].fillna('')\n",
    "sample_s = review_panel_text.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process via spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple apple PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. u.k. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "he -PRON- PRON PRP nsubj xx True True\n",
      "his -PRON- ADJ PRP$ ROOT xxx True True\n",
      "him -PRON- PRON PRP dobj xxx True True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion. he his him')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-',\n",
       " 'say',\n",
       " 'that',\n",
       " '-PRON-',\n",
       " 'do',\n",
       " 'not',\n",
       " 'buy',\n",
       " 'apple',\n",
       " 'for',\n",
       " 'her',\n",
       " '.',\n",
       " 'I',\n",
       " 'my',\n",
       " 'me',\n",
       " 'mine']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_keep= set(['he','his','him', 'she','her', 'I','my','me','mine'])\n",
    "def lemma(x):\n",
    "    if x.text in words_to_keep: \n",
    "        return x.text\n",
    "    elif x.text not in words_to_keep:\n",
    "        return x.lemma_\n",
    "    \n",
    "    \n",
    "a_doc = nlp(\"He said that you didn't buy apples for her. I my me mine\")  # feed in string or documents\n",
    "[lemma(x) for x in a_doc]   # lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['great',\n",
       "  'result',\n",
       "  'anderson',\n",
       "  'explain',\n",
       "  'in',\n",
       "  'detail',\n",
       "  'my',\n",
       "  'option',\n",
       "  'for',\n",
       "  'the',\n",
       "  'repair',\n",
       "  'on',\n",
       "  'my',\n",
       "  'tooth',\n",
       "  'in',\n",
       "  'the',\n",
       "  'end',\n",
       "  'I',\n",
       "  'receive',\n",
       "  'great',\n",
       "  'result'],\n",
       " ['implant',\n",
       "  'have',\n",
       "  'an',\n",
       "  'implant',\n",
       "  'do',\n",
       "  'and',\n",
       "  '-PRON-',\n",
       "  'be',\n",
       "  'painless',\n",
       "  'I',\n",
       "  'could',\n",
       "  'not',\n",
       "  'afford',\n",
       "  '-PRON-',\n",
       "  'so',\n",
       "  'he',\n",
       "  'put',\n",
       "  'me',\n",
       "  'on',\n",
       "  'a',\n",
       "  'payment',\n",
       "  'plan',\n",
       "  'I',\n",
       "  'be',\n",
       "  'pleased',\n",
       "  'with',\n",
       "  'the',\n",
       "  'service',\n",
       "  'great'],\n",
       " ['warning',\n",
       "  'would',\n",
       "  'not',\n",
       "  'see',\n",
       "  'this',\n",
       "  'dentist',\n",
       "  'do',\n",
       "  'not',\n",
       "  'go',\n",
       "  'to',\n",
       "  'this',\n",
       "  'dentist',\n",
       "  'office',\n",
       "  '-PRON-',\n",
       "  'scam',\n",
       "  'people',\n",
       "  'and',\n",
       "  'do',\n",
       "  'not',\n",
       "  'pay',\n",
       "  'there',\n",
       "  'bill',\n",
       "  '-PRON-',\n",
       "  'snow',\n",
       "  'plow',\n",
       "  'for',\n",
       "  '-PRON-',\n",
       "  'and',\n",
       "  'when',\n",
       "  'the',\n",
       "  'season',\n",
       "  'be',\n",
       "  'over',\n",
       "  '-PRON-',\n",
       "  'would',\n",
       "  'not',\n",
       "  'pay',\n",
       "  '-PRON-',\n",
       "  'this',\n",
       "  'be',\n",
       "  'just',\n",
       "  'to',\n",
       "  'let',\n",
       "  '-PRON-',\n",
       "  'know',\n",
       "  'what',\n",
       "  'type',\n",
       "  'of',\n",
       "  'dentist',\n",
       "  '-PRON-',\n",
       "  'deal',\n",
       "  'with'],\n",
       " ['very', 'thoughtful', 'communicatesbedside', 'manner', 'great'],\n",
       " ['larsen',\n",
       "  'great',\n",
       "  'other',\n",
       "  'no',\n",
       "  'would',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'see',\n",
       "  'larsen',\n",
       "  'however',\n",
       "  'his',\n",
       "  'front',\n",
       "  'desk',\n",
       "  'secretary',\n",
       "  'be',\n",
       "  'something',\n",
       "  'else',\n",
       "  '-PRON-',\n",
       "  'sadden',\n",
       "  'me',\n",
       "  'to',\n",
       "  'have',\n",
       "  'to',\n",
       "  'give',\n",
       "  'my',\n",
       "  'money',\n",
       "  'to',\n",
       "  'someone',\n",
       "  'else']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize and fitler documents; deal with punctuation and typo (2h 30mins)\n",
    "terms_list=[]\n",
    "words_to_filter = set(['dr', 'doctor', 'oh'])\n",
    "words_to_keep = set(['he','his','him','she','her','I','my','me','mine'])\n",
    "def lemma(x):\n",
    "    if x.text in words_to_keep: \n",
    "        return x.text\n",
    "    elif x.text not in words_to_keep:\n",
    "        return x.lemma_\n",
    "\n",
    "for doc in sample_s:\n",
    "    doc_cleared = textacy.preprocess_text(doc, lowercase=False, no_punct=True, transliterate=True)\n",
    "    doc_new = nlp(doc_cleared)\n",
    "    tokens=[lemma(x) for x in doc_new]  #keep pronoun\n",
    "    tokens_filtered = [y for y in tokens if y not in words_to_filter]\n",
    "    terms_list.append(tokens_filtered)\n",
    "\n",
    "terms_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the corpus as a txt file (2 min)\n",
    "with open(\"./data/terms_list_sample.txt\",\"w\") as thefile:\n",
    "    for item in terms_list:\n",
    "      thefile.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model via word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in corpus\n",
    "sts_terms_list = gensim.models.word2vec.LineSentence('terms_list_sample.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train word2vec on the corpus (10 mins)\n",
    "model = gensim.models.Word2Vec(sentences=terms_list, size=100, window=7, min_count=5, workers=4)\n",
    "# to save a trained model\n",
    "model.save(\"./data/model_doc_comments1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "model = gensim.models.Word2Vec.load(\"./data/model_doc_comments1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To convert documents to vectors (10 min)\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(terms_list)\n",
    "# store the dictionary, for future reference\n",
    "dictionary.save('./data/try_dictionary.dict')\n",
    "#print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "# To see the mapping between words and their ids\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8985168 ,  0.21133737, -1.0174987 ,  0.23950161,  0.6535615 ,\n",
       "       -2.1597543 , -0.96719617, -1.2723322 ,  0.6952619 ,  0.52317786,\n",
       "        3.8957522 , -4.2797956 , -3.5484123 ,  2.9083505 , -2.0390408 ,\n",
       "        1.4697789 ,  2.7010856 , -2.316967  ,  1.357116  ,  2.9058228 ,\n",
       "       -1.5485703 , -2.5820878 ,  1.5781274 , -4.7464647 ,  2.5480347 ,\n",
       "       -1.0955589 , -4.0962763 ,  2.5019717 , -1.9741727 ,  2.3681483 ,\n",
       "        2.2892256 , -1.7966137 ,  2.341933  ,  1.9638792 ,  1.0589308 ,\n",
       "       -3.6643832 ,  0.8503319 ,  2.3559475 ,  0.8861464 ,  2.4579482 ,\n",
       "        0.09558363, -1.3544432 , -1.3810408 ,  3.4680386 , -2.2576418 ,\n",
       "       -1.45918   ,  1.1770133 ,  0.47717357,  0.82000923,  1.227406  ,\n",
       "       -3.9137058 , -0.06107468, -0.597307  , -2.9509046 , -1.9264892 ,\n",
       "       -0.3778871 , -1.1883132 ,  2.1589031 , -0.23421006,  0.4014843 ,\n",
       "       -1.801502  , -2.567079  , -1.50274   , -1.3262734 ,  1.2228625 ,\n",
       "       -3.5384681 ,  2.4423347 ,  1.5887536 ,  1.7367889 ,  0.56629264,\n",
       "       -2.976403  ,  1.7316047 ,  0.85862345, -4.0094047 , -1.3027035 ,\n",
       "       -0.02309173,  0.14540017, -1.4939944 ,  2.3036516 , -4.358884  ,\n",
       "        0.6274549 ,  1.6369541 , -1.5460306 ,  1.5804508 ,  2.087859  ,\n",
       "        0.091611  , -1.0865207 , -1.2028426 ,  2.2024171 , -0.512689  ,\n",
       "        1.8277788 ,  4.8530684 , -1.461438  , -4.029867  ,  1.0429525 ,\n",
       "        0.01837958,  2.701353  ,  0.3471363 , -2.8164046 , -0.8185738 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['I']  # numpy vector of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaowan/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.8985168 ,  0.21133737, -1.0174987 ,  0.23950161,  0.6535615 ,\n",
       "       -2.1597543 , -0.96719617, -1.2723322 ,  0.6952619 ,  0.52317786,\n",
       "        3.8957522 , -4.2797956 , -3.5484123 ,  2.9083505 , -2.0390408 ,\n",
       "        1.4697789 ,  2.7010856 , -2.316967  ,  1.357116  ,  2.9058228 ,\n",
       "       -1.5485703 , -2.5820878 ,  1.5781274 , -4.7464647 ,  2.5480347 ,\n",
       "       -1.0955589 , -4.0962763 ,  2.5019717 , -1.9741727 ,  2.3681483 ,\n",
       "        2.2892256 , -1.7966137 ,  2.341933  ,  1.9638792 ,  1.0589308 ,\n",
       "       -3.6643832 ,  0.8503319 ,  2.3559475 ,  0.8861464 ,  2.4579482 ,\n",
       "        0.09558363, -1.3544432 , -1.3810408 ,  3.4680386 , -2.2576418 ,\n",
       "       -1.45918   ,  1.1770133 ,  0.47717357,  0.82000923,  1.227406  ,\n",
       "       -3.9137058 , -0.06107468, -0.597307  , -2.9509046 , -1.9264892 ,\n",
       "       -0.3778871 , -1.1883132 ,  2.1589031 , -0.23421006,  0.4014843 ,\n",
       "       -1.801502  , -2.567079  , -1.50274   , -1.3262734 ,  1.2228625 ,\n",
       "       -3.5384681 ,  2.4423347 ,  1.5887536 ,  1.7367889 ,  0.56629264,\n",
       "       -2.976403  ,  1.7316047 ,  0.85862345, -4.0094047 , -1.3027035 ,\n",
       "       -0.02309173,  0.14540017, -1.4939944 ,  2.3036516 , -4.358884  ,\n",
       "        0.6274549 ,  1.6369541 , -1.5460306 ,  1.5804508 ,  2.087859  ,\n",
       "        0.091611  , -1.0865207 , -1.2028426 ,  2.2024171 , -0.512689  ,\n",
       "        1.8277788 ,  4.8530684 , -1.461438  , -4.029867  ,  1.0429525 ,\n",
       "        0.01837958,  2.701353  ,  0.3471363 , -2.8164046 , -0.8185738 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
