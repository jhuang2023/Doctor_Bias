{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "import gensim\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>href</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>Ease_of_Appointment</th>\n",
       "      <th>Promptness</th>\n",
       "      <th>Courteous_Staff</th>\n",
       "      <th>Accurate_Diagnosis</th>\n",
       "      <th>Bedside_Manner</th>\n",
       "      <th>Spends_Time_with_Me</th>\n",
       "      <th>...</th>\n",
       "      <th>Advanced_Technology</th>\n",
       "      <th>Caring_Manner</th>\n",
       "      <th>Pain_Minimized</th>\n",
       "      <th>Satisfaction</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>crawl_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12949966</td>\n",
       "      <td>23507540</td>\n",
       "      <td>/dentists/Dr_Aarika_Anderson_Elter</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-11-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Great results</td>\n",
       "      <td>Dr. Anderson explained in detail my options fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12949967</td>\n",
       "      <td>27184431</td>\n",
       "      <td>/dentists/Dr_Aamir_Wahab</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-03-15</td>\n",
       "      <td>Brad s.</td>\n",
       "      <td>implant</td>\n",
       "      <td>Had an implant done and it was painless. I cou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12949968</td>\n",
       "      <td>26307282</td>\n",
       "      <td>/dentists/Dr_Aanal_Parikh</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-10-12</td>\n",
       "      <td>Bill johnson</td>\n",
       "      <td>Warning ..would not see this dentist</td>\n",
       "      <td>Do not go to this dentist office they scam peo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12949969</td>\n",
       "      <td>28904504</td>\n",
       "      <td>/dentists/Dr_Aaron_Aguilar</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very thoughtful Dr.  Communicates/bedside mann...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12949970</td>\n",
       "      <td>28380953</td>\n",
       "      <td>/dentists/Dr_Aaron_D_Larsen</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dr larsen great others no</td>\n",
       "      <td>Would continue to see Dr.  Larsen however his ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-06 20:54:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  review_id                                href  overall_rating  \\\n",
       "0  12949966   23507540  /dentists/Dr_Aarika_Anderson_Elter               5   \n",
       "1  12949967   27184431            /dentists/Dr_Aamir_Wahab               5   \n",
       "2  12949968   26307282           /dentists/Dr_Aanal_Parikh               1   \n",
       "3  12949969   28904504          /dentists/Dr_Aaron_Aguilar               5   \n",
       "4  12949970   28380953         /dentists/Dr_Aaron_D_Larsen               4   \n",
       "\n",
       "   Ease_of_Appointment  Promptness  Courteous_Staff  Accurate_Diagnosis  \\\n",
       "0                  4.0         NaN              NaN                 NaN   \n",
       "1                  5.0         NaN              NaN                 NaN   \n",
       "2                  1.0         NaN              NaN                 NaN   \n",
       "3                  5.0         NaN              NaN                 NaN   \n",
       "4                  3.0         NaN              NaN                 NaN   \n",
       "\n",
       "   Bedside_Manner  Spends_Time_with_Me         ...           \\\n",
       "0             NaN                  NaN         ...            \n",
       "1             NaN                  NaN         ...            \n",
       "2             NaN                  NaN         ...            \n",
       "3             NaN                  NaN         ...            \n",
       "4             NaN                  NaN         ...            \n",
       "\n",
       "   Advanced_Technology  Caring_Manner  Pain_Minimized  Satisfaction  \\\n",
       "0                  NaN            5.0             5.0           NaN   \n",
       "1                  5.0            5.0             5.0           5.0   \n",
       "2                  1.0            1.0             1.0           1.0   \n",
       "3                  5.0            5.0             5.0           5.0   \n",
       "4                  4.0            4.0             4.0           5.0   \n",
       "\n",
       "         date      reviewer                                 title  \\\n",
       "0  2012-11-16           NaN                        Great results    \n",
       "1  2015-03-15       Brad s.                               implant   \n",
       "2  2014-10-12  Bill johnson  Warning ..would not see this dentist   \n",
       "3  2015-06-11           NaN                                   NaN   \n",
       "4  2015-03-31           NaN             Dr larsen great others no   \n",
       "\n",
       "                                             content helpful_vote  \\\n",
       "0  Dr. Anderson explained in detail my options fo...          NaN   \n",
       "1  Had an implant done and it was painless. I cou...          NaN   \n",
       "2  Do not go to this dentist office they scam peo...          NaN   \n",
       "3  Very thoughtful Dr.  Communicates/bedside mann...          NaN   \n",
       "4  Would continue to see Dr.  Larsen however his ...          NaN   \n",
       "\n",
       "            crawl_date  \n",
       "0  2016-09-06 20:54:01  \n",
       "1  2016-09-06 20:54:10  \n",
       "2  2016-09-06 20:54:13  \n",
       "3  2016-09-06 20:54:14  \n",
       "4  2016-09-06 20:54:18  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_panel = pd.read_csv('./data/reviews_panel_t8.csv')\n",
    "review_panel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1796204, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_panel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "review_panel_text = review_panel['title'].fillna('').astype(str) + \" \" + review_panel['content'].fillna('')\n",
    "sample_s = review_panel_text.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Pre-process via spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple apple PROPN NNP nsubj Xxxxx True False\n",
      "is be VERB VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. u.k. PROPN NNP compound X.X. False False\n",
      "startup startup NOUN NN dobj xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n",
      "he -PRON- PRON PRP nsubj xx True True\n",
      "his -PRON- ADJ PRP$ ROOT xxx True True\n",
      "him -PRON- PRON PRP dobj xxx True True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion. he his him')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-PRON-', 'say', 'that', '-PRON-', 'do', 'not', 'buy', 'apple', 'for', 'her', '.', 'but', 'I', 'buy', 'mine', '.']\n"
     ]
    }
   ],
   "source": [
    "words_to_keep= set(['he','his','him', 'she','her', 'I','my','me','mine'])\n",
    "def lemma(x):\n",
    "    if x.text in words_to_keep: \n",
    "        return x.text\n",
    "    elif x.text not in words_to_keep:\n",
    "        return x.lemma_\n",
    "    \n",
    "    \n",
    "a_doc = nlp(\"He said that you didn't buy apples for her. But I bought mine.\")  # feed in string or documents\n",
    "print([lemma(x) for x in a_doc])   # lemmatize words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['great',\n",
       "  'result',\n",
       "  'anderson',\n",
       "  'explain',\n",
       "  'in',\n",
       "  'detail',\n",
       "  'my',\n",
       "  'option',\n",
       "  'for',\n",
       "  'the',\n",
       "  'repair',\n",
       "  'on',\n",
       "  'my',\n",
       "  'tooth',\n",
       "  'in',\n",
       "  'the',\n",
       "  'end',\n",
       "  'I',\n",
       "  'receive',\n",
       "  'great',\n",
       "  'result'],\n",
       " ['implant',\n",
       "  'have',\n",
       "  'an',\n",
       "  'implant',\n",
       "  'do',\n",
       "  'and',\n",
       "  '-PRON-',\n",
       "  'be',\n",
       "  'painless',\n",
       "  'I',\n",
       "  'could',\n",
       "  'not',\n",
       "  'afford',\n",
       "  '-PRON-',\n",
       "  'so',\n",
       "  'he',\n",
       "  'put',\n",
       "  'me',\n",
       "  'on',\n",
       "  'a',\n",
       "  'payment',\n",
       "  'plan',\n",
       "  'I',\n",
       "  'be',\n",
       "  'pleased',\n",
       "  'with',\n",
       "  'the',\n",
       "  'service',\n",
       "  'great'],\n",
       " ['warning',\n",
       "  'would',\n",
       "  'not',\n",
       "  'see',\n",
       "  'this',\n",
       "  'dentist',\n",
       "  'do',\n",
       "  'not',\n",
       "  'go',\n",
       "  'to',\n",
       "  'this',\n",
       "  'dentist',\n",
       "  'office',\n",
       "  '-PRON-',\n",
       "  'scam',\n",
       "  'people',\n",
       "  'and',\n",
       "  'do',\n",
       "  'not',\n",
       "  'pay',\n",
       "  'there',\n",
       "  'bill',\n",
       "  '-PRON-',\n",
       "  'snow',\n",
       "  'plow',\n",
       "  'for',\n",
       "  '-PRON-',\n",
       "  'and',\n",
       "  'when',\n",
       "  'the',\n",
       "  'season',\n",
       "  'be',\n",
       "  'over',\n",
       "  '-PRON-',\n",
       "  'would',\n",
       "  'not',\n",
       "  'pay',\n",
       "  '-PRON-',\n",
       "  'this',\n",
       "  'be',\n",
       "  'just',\n",
       "  'to',\n",
       "  'let',\n",
       "  '-PRON-',\n",
       "  'know',\n",
       "  'what',\n",
       "  'type',\n",
       "  'of',\n",
       "  'dentist',\n",
       "  '-PRON-',\n",
       "  'deal',\n",
       "  'with'],\n",
       " ['very', 'thoughtful', 'communicatesbedside', 'manner', 'great'],\n",
       " ['larsen',\n",
       "  'great',\n",
       "  'other',\n",
       "  'no',\n",
       "  'would',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'see',\n",
       "  'larsen',\n",
       "  'however',\n",
       "  'his',\n",
       "  'front',\n",
       "  'desk',\n",
       "  'secretary',\n",
       "  'be',\n",
       "  'something',\n",
       "  'else',\n",
       "  '-PRON-',\n",
       "  'sadden',\n",
       "  'me',\n",
       "  'to',\n",
       "  'have',\n",
       "  'to',\n",
       "  'give',\n",
       "  'my',\n",
       "  'money',\n",
       "  'to',\n",
       "  'someone',\n",
       "  'else']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize and fitler documents; deal with punctuation and typo (2h 30mins)\n",
    "terms_list=[]\n",
    "words_to_filter = set(['dr', 'doctor', 'oh'])\n",
    "words_to_keep = set(['he','his','him','she','her','I','my','me','mine'])\n",
    "def lemma(x):\n",
    "    if x.text in words_to_keep: \n",
    "        return x.text\n",
    "    elif x.text not in words_to_keep:\n",
    "        return x.lemma_\n",
    "\n",
    "for doc in sample_s:\n",
    "    doc_cleared = textacy.preprocess_text(doc, lowercase=False, no_punct=True, transliterate=True)\n",
    "    doc_new = nlp(doc_cleared)\n",
    "    tokens=[lemma(x) for x in doc_new]  #to keep pronouns\n",
    "    tokens_filtered = [y for y in tokens if y not in words_to_filter]\n",
    "    terms_list.append(tokens_filtered)\n",
    "\n",
    "print(terms_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save the corpus as a txt file (2 min)\n",
    "with open(\"./data/terms_list.txt\",\"w\") as thefile:\n",
    "    for item in terms_list:\n",
    "      thefile.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great', 'result', 'anderson', 'explain', 'in', 'detail', 'my', 'option', 'for', 'the', 'repair', 'on', 'my', 'tooth', 'in', 'the', 'end', 'I', 'receive', 'great', 'result']\n",
      "['implant', 'have', 'an', 'implant', 'do', 'and', '-PRON-', 'be', 'painless', 'I', 'could', 'not', 'afford', '-PRON-', 'so', 'he', 'put', 'me', 'on', 'a', 'payment', 'plan', 'I', 'be', 'pleased', 'with', 'the', 'service', 'great']\n",
      "['warning', 'would', 'not', 'see', 'this', 'dentist', 'do', 'not', 'go', 'to', 'this', 'dentist', 'office', '-PRON-', 'scam', 'people', 'and', 'do', 'not', 'pay', 'there', 'bill', '-PRON-', 'snow', 'plow', 'for', '-PRON-', 'and', 'when', 'the', 'season', 'be', 'over', '-PRON-', 'would', 'not', 'pay', '-PRON-', 'this', 'be', 'just', 'to', 'let', '-PRON-', 'know', 'what', 'type', 'of', 'dentist', '-PRON-', 'deal', 'with']\n",
      "['very', 'thoughtful', 'communicatesbedside', 'manner', 'great']\n",
      "['larsen', 'great', 'other', 'no', 'would', 'continue', 'to', 'see', 'larsen', 'however', 'his', 'front', 'desk', 'secretary', 'be', 'something', 'else', '-PRON-', 'sadden', 'me', 'to', 'have', 'to', 'give', 'my', 'money', 'to', 'someone', 'else']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file= open('./data/terms_list.txt','r')\n",
    "terms=file.read()\n",
    "print(terms[:1143])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Build model via word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# read in corpus\n",
    "sts_terms_list = gensim.models.word2vec.LineSentence('terms_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train word2vec on the corpus (10 mins)\n",
    "model = gensim.models.Word2Vec(sentences=terms_list, size=100, window=7, min_count=5, workers=4)\n",
    "# to save a trained model\n",
    "model.save(\"./data/model_doc_comments1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8985168 ,  0.21133737, -1.0174987 ,  0.23950161,  0.6535615 ,\n",
       "       -2.1597543 , -0.96719617, -1.2723322 ,  0.6952619 ,  0.52317786,\n",
       "        3.8957522 , -4.2797956 , -3.5484123 ,  2.9083505 , -2.0390408 ,\n",
       "        1.4697789 ,  2.7010856 , -2.316967  ,  1.357116  ,  2.9058228 ,\n",
       "       -1.5485703 , -2.5820878 ,  1.5781274 , -4.7464647 ,  2.5480347 ,\n",
       "       -1.0955589 , -4.0962763 ,  2.5019717 , -1.9741727 ,  2.3681483 ,\n",
       "        2.2892256 , -1.7966137 ,  2.341933  ,  1.9638792 ,  1.0589308 ,\n",
       "       -3.6643832 ,  0.8503319 ,  2.3559475 ,  0.8861464 ,  2.4579482 ,\n",
       "        0.09558363, -1.3544432 , -1.3810408 ,  3.4680386 , -2.2576418 ,\n",
       "       -1.45918   ,  1.1770133 ,  0.47717357,  0.82000923,  1.227406  ,\n",
       "       -3.9137058 , -0.06107468, -0.597307  , -2.9509046 , -1.9264892 ,\n",
       "       -0.3778871 , -1.1883132 ,  2.1589031 , -0.23421006,  0.4014843 ,\n",
       "       -1.801502  , -2.567079  , -1.50274   , -1.3262734 ,  1.2228625 ,\n",
       "       -3.5384681 ,  2.4423347 ,  1.5887536 ,  1.7367889 ,  0.56629264,\n",
       "       -2.976403  ,  1.7316047 ,  0.85862345, -4.0094047 , -1.3027035 ,\n",
       "       -0.02309173,  0.14540017, -1.4939944 ,  2.3036516 , -4.358884  ,\n",
       "        0.6274549 ,  1.6369541 , -1.5460306 ,  1.5804508 ,  2.087859  ,\n",
       "        0.091611  , -1.0865207 , -1.2028426 ,  2.2024171 , -0.512689  ,\n",
       "        1.8277788 ,  4.8530684 , -1.461438  , -4.029867  ,  1.0429525 ,\n",
       "        0.01837958,  2.701353  ,  0.3471363 , -2.8164046 , -0.8185738 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['I']  # numpy vector of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaowan/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.8985168 ,  0.21133737, -1.0174987 ,  0.23950161,  0.6535615 ,\n",
       "       -2.1597543 , -0.96719617, -1.2723322 ,  0.6952619 ,  0.52317786,\n",
       "        3.8957522 , -4.2797956 , -3.5484123 ,  2.9083505 , -2.0390408 ,\n",
       "        1.4697789 ,  2.7010856 , -2.316967  ,  1.357116  ,  2.9058228 ,\n",
       "       -1.5485703 , -2.5820878 ,  1.5781274 , -4.7464647 ,  2.5480347 ,\n",
       "       -1.0955589 , -4.0962763 ,  2.5019717 , -1.9741727 ,  2.3681483 ,\n",
       "        2.2892256 , -1.7966137 ,  2.341933  ,  1.9638792 ,  1.0589308 ,\n",
       "       -3.6643832 ,  0.8503319 ,  2.3559475 ,  0.8861464 ,  2.4579482 ,\n",
       "        0.09558363, -1.3544432 , -1.3810408 ,  3.4680386 , -2.2576418 ,\n",
       "       -1.45918   ,  1.1770133 ,  0.47717357,  0.82000923,  1.227406  ,\n",
       "       -3.9137058 , -0.06107468, -0.597307  , -2.9509046 , -1.9264892 ,\n",
       "       -0.3778871 , -1.1883132 ,  2.1589031 , -0.23421006,  0.4014843 ,\n",
       "       -1.801502  , -2.567079  , -1.50274   , -1.3262734 ,  1.2228625 ,\n",
       "       -3.5384681 ,  2.4423347 ,  1.5887536 ,  1.7367889 ,  0.56629264,\n",
       "       -2.976403  ,  1.7316047 ,  0.85862345, -4.0094047 , -1.3027035 ,\n",
       "       -0.02309173,  0.14540017, -1.4939944 ,  2.3036516 , -4.358884  ,\n",
       "        0.6274549 ,  1.6369541 , -1.5460306 ,  1.5804508 ,  2.087859  ,\n",
       "        0.091611  , -1.0865207 , -1.2028426 ,  2.2024171 , -0.512689  ,\n",
       "        1.8277788 ,  4.8530684 , -1.461438  , -4.029867  ,  1.0429525 ,\n",
       "        0.01837958,  2.701353  ,  0.3471363 , -2.8164046 , -0.8185738 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['I']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure the stereotype bias\n",
    "- via comparison of comments on female and male physicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "model = gensim.models.Word2Vec.load(\"./data/model_doc_comments1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: word analogies generated by model\n",
    "- __analogy__ 'he' + (adj.) - 'she' = ? |  __converse__ 'she' + (adj.) - 'he' = ?\n",
    "- __analogy__ 'his' + (noun) - 'her' = ? |  __converse__ 'her' + (noun) - 'his' = ?\n",
    "- __To be noticed: Results heavily relies on the choice of keyword pairs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Part 1: analogy  'he' + (adj.) - 'she' = ?  |  converse 'she' + (adj.) - 'he' = ?\n",
    "- keywords_adj_1 = {'professional','efficient','competent'}\n",
    "- keywords_adj_2 = {'nice',__'friendly','polite'__}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('proffesional', 0.6564347743988037),\n",
       " ('proffessional', 0.6406091451644897),\n",
       " ('personable', 0.6229191422462463),\n",
       " ('professionalhe', 0.6222789883613586),\n",
       " ('knowledgeable', 0.6085402369499207),\n",
       " ('humble', 0.608481228351593),\n",
       " ('professionali', 0.6083875894546509),\n",
       " ('competent', 0.6081501841545105),\n",
       " ('efficient', 0.6004852056503296),\n",
       " ('knowledgable', 0.5969569087028503)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('efficient', 0.6449151039123535),\n",
       " ('helpful', 0.6382687091827393),\n",
       " ('polite', 0.6301308274269104),\n",
       " ('proffesional', 0.623944878578186),\n",
       " ('attentive', 0.6222675442695618),\n",
       " ('respectful', 0.6202351450920105),\n",
       " ('warm', 0.6143782138824463),\n",
       " ('friendly', 0.6115367412567139),\n",
       " ('personable', 0.599821925163269),\n",
       " ('supportive', 0.5963608026504517)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# he+(adj.)-she\n",
    "model.wv.most_similar(positive=['he', 'professional'], negative=['she'], topn=10)\n",
    "# she+(adj.)-he\n",
    "model.wv.most_similar(positive=['she', 'professional'], negative=['he'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beneficial', 0.6459837555885315),\n",
       " ('conservative', 0.6394050121307373),\n",
       " ('innovative', 0.5897181034088135),\n",
       " ('economical', 0.5809915661811829),\n",
       " ('noninvasive', 0.572291910648346),\n",
       " ('prudent', 0.5711985230445862),\n",
       " ('prolotherapy', 0.5664175152778625),\n",
       " ('inexpensive', 0.5597268342971802),\n",
       " ('exacting', 0.5417249202728271),\n",
       " ('controversial', 0.5396667122840881)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('agreeable', 0.5745129585266113),\n",
       " ('economical', 0.5587084293365479),\n",
       " ('pragmatic', 0.54994797706604),\n",
       " ('beneficial', 0.5498460531234741),\n",
       " ('insightful', 0.5408653020858765),\n",
       " ('therapeutic', 0.5386779308319092),\n",
       " ('proactive', 0.5321661829948425),\n",
       " ('efficacious', 0.5267099738121033),\n",
       " ('openminded', 0.5205910801887512),\n",
       " ('astute', 0.5198585987091064)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# he+(adj.)-she\n",
    "model.wv.most_similar(positive=['he', 'effective'], negative=['she'], topn=10)\n",
    "# she+(adj.)-he\n",
    "model.wv.most_similar(positive=['she', 'effective'], negative=['he'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('skilled', 0.7663887143135071),\n",
       " ('capable', 0.7054327726364136),\n",
       " ('proficient', 0.7037885189056396),\n",
       " ('competant', 0.6754753589630127),\n",
       " ('talented', 0.673223078250885),\n",
       " ('experienced', 0.6638932228088379),\n",
       " ('skillful', 0.656440019607544),\n",
       " ('qualified', 0.6559319496154785),\n",
       " ('intelligent', 0.6537479758262634),\n",
       " ('knowledgeable', 0.6486888527870178)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('competant', 0.7423862218856812),\n",
       " ('capable', 0.6668056845664978),\n",
       " ('knowlegeable', 0.6394909620285034),\n",
       " ('proficient', 0.6360024213790894),\n",
       " ('knowledgable', 0.6337969303131104),\n",
       " ('knowledgeable', 0.6328122019767761),\n",
       " ('welltrain', 0.6277335286140442),\n",
       " ('experienced', 0.6254478096961975),\n",
       " ('knowlegable', 0.6198614835739136),\n",
       " ('engaged', 0.6171719431877136)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# he+(adj.)-she\n",
    "model.wv.most_similar(positive=['he', 'competent'], negative=['she'], topn=10)\n",
    "# she+(adj.)-he\n",
    "model.wv.most_similar(positive=['she', 'competent'], negative=['he'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('friendly', 0.6206178665161133),\n",
       " ('polite', 0.6170006394386292),\n",
       " ('likable', 0.6024885177612305),\n",
       " ('pleasant', 0.5870307683944702),\n",
       " ('friendy', 0.5755089521408081),\n",
       " ('likeable', 0.5656896829605103),\n",
       " ('pleasent', 0.5615097284317017),\n",
       " ('plesant', 0.5488872528076172),\n",
       " ('cool', 0.5443068742752075),\n",
       " ('charming', 0.543339192867279)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('sweet', 0.8070353865623474),\n",
       " ('lovely', 0.6870039701461792),\n",
       " ('friendly', 0.68165123462677),\n",
       " ('polite', 0.6418354511260986),\n",
       " ('pleasant', 0.623091995716095),\n",
       " ('pleasent', 0.6188926696777344),\n",
       " ('welcoming', 0.6035218834877014),\n",
       " ('unfriendly', 0.6007041335105896),\n",
       " ('snotty', 0.5943301320075989),\n",
       " ('plesant', 0.5931156277656555)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# he+(adj.)-she\n",
    "model.wv.most_similar(positive=['he', 'nice'], negative=['she'], topn=10)\n",
    "# she+(adj.)-he\n",
    "model.wv.most_similar(positive=['she', 'nice'], negative=['he'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('polite', 0.780290961265564),\n",
       " ('courteous', 0.7779586911201477),\n",
       " ('pleasant', 0.6985913515090942),\n",
       " ('personable', 0.6834683418273926),\n",
       " ('cordial', 0.6830505132675171),\n",
       " ('efficient', 0.6762321591377258),\n",
       " ('curteous', 0.6745314598083496),\n",
       " ('nice', 0.6646460294723511),\n",
       " ('curtious', 0.6569429039955139),\n",
       " ('courtious', 0.6483271718025208)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('polite', 0.7677793502807617),\n",
       " ('helpful', 0.7214754223823547),\n",
       " ('courteous', 0.7051953673362732),\n",
       " ('pleasant', 0.7012017965316772),\n",
       " ('sweet', 0.6971908807754517),\n",
       " ('welcoming', 0.6816627979278564),\n",
       " ('accomodat', 0.6815884113311768),\n",
       " ('cheerful', 0.6797686219215393),\n",
       " ('accommodating', 0.6655685901641846),\n",
       " ('cordial', 0.6591864824295044)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# he+(adj.)-she\n",
    "model.wv.most_similar(positive=['he', 'friendly'], negative=['she'], topn=10)\n",
    "# she+(adj.)-he\n",
    "model.wv.most_similar(positive=['she', 'friendly'], negative=['he'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.777746319770813),\n",
       " ('friendly', 0.74969482421875),\n",
       " ('cordial', 0.7161503434181213),\n",
       " ('curteous', 0.7138438820838928),\n",
       " ('courtious', 0.6966575384140015),\n",
       " ('curtious', 0.6917126178741455),\n",
       " ('personable', 0.6851114630699158),\n",
       " ('efficient', 0.6846919059753418),\n",
       " ('helpful', 0.6555166244506836),\n",
       " ('helpfull', 0.650011420249939)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('friendly', 0.796964704990387),\n",
       " ('helpful', 0.7659982442855835),\n",
       " ('courteous', 0.7271215319633484),\n",
       " ('cordial', 0.7114821076393127),\n",
       " ('sweet', 0.7110629081726074),\n",
       " ('curtious', 0.706183135509491),\n",
       " ('curteous', 0.6957941055297852),\n",
       " ('accomodat', 0.6941994428634644),\n",
       " ('accommodating', 0.6795791983604431),\n",
       " ('courtious', 0.671298086643219)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# he+(adj.)-she\n",
    "model.wv.most_similar(positive=['he', 'polite'], negative=['she'], topn=10)\n",
    "# she+(adj.)-he\n",
    "model.wv.most_similar(positive=['she', 'polite'], negative=['he'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: analogy 'his' + (noun) - 'her' = ?  |  converse 'her' + (noun) - 'his' = ?\n",
    "- keywords_n_1 = {'technique','methodology','execution'}\n",
    "- keywords_n_2 = {'smile','grin',__'warm'__}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('technology', 0.60670006275177),\n",
       " ('cuttingedge', 0.5887786746025085),\n",
       " ('innovative', 0.5801389813423157),\n",
       " ('precision', 0.570105791091919),\n",
       " ('surgical', 0.5657679438591003),\n",
       " ('aesthetic', 0.5644391179084778),\n",
       " ('artistry', 0.5632181763648987),\n",
       " ('execution', 0.5563507676124573),\n",
       " ('technical', 0.5525886416435242),\n",
       " ('methodology', 0.544705867767334)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('technic', 0.5587255358695984),\n",
       " ('method', 0.5398416519165039),\n",
       " ('technology', 0.5327882766723633),\n",
       " ('tool', 0.5315686464309692),\n",
       " ('instrument', 0.46823790669441223),\n",
       " ('methodology', 0.4624430537223816),\n",
       " ('advancement', 0.46089014410972595),\n",
       " ('brava', 0.4550757110118866),\n",
       " ('vaseline', 0.4540991187095642),\n",
       " ('hrt', 0.45188942551612854)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# his+(noun)-her\n",
    "model.wv.most_similar(positive=['his', 'technique'], negative=['her'], topn=10)\n",
    "# her+(noun)-his\n",
    "model.wv.most_similar(positive=['her', 'technique'], negative=['his'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scientific', 0.6270068883895874),\n",
       " ('cuttingedge', 0.6237863302230835),\n",
       " ('innovative', 0.6234255433082581),\n",
       " ('execution', 0.6092877984046936),\n",
       " ('evidencebased', 0.5992555022239685),\n",
       " ('procedural', 0.5958627462387085),\n",
       " ('technique', 0.5914133191108704),\n",
       " ('mastery', 0.5861795544624329),\n",
       " ('pharmacology', 0.583117663860321),\n",
       " ('technical', 0.5739743113517761)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('method', 0.5421013236045837),\n",
       " ('therapeutic', 0.535122275352478),\n",
       " ('strategy', 0.5350595712661743),\n",
       " ('approach', 0.5251684188842773),\n",
       " ('commonsense', 0.5161302089691162),\n",
       " ('logic', 0.5129414796829224),\n",
       " ('theory', 0.5114564299583435),\n",
       " ('naturopathic', 0.5072319507598877),\n",
       " ('regimen', 0.5017905831336975),\n",
       " ('homeopathy', 0.4981175661087036)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# his+(noun)-her\n",
    "model.wv.most_similar(positive=['his', 'methodology'], negative=['her'], topn=10)\n",
    "# her+(noun)-his\n",
    "model.wv.most_similar(positive=['her', 'methodology'], negative=['his'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('precision', 0.6059291958808899),\n",
       " ('surgical', 0.5837683081626892),\n",
       " ('procedural', 0.5648508071899414),\n",
       " ('execute', 0.5634226202964783),\n",
       " ('bydons', 0.5609303116798401),\n",
       " ('perfectionism', 0.5564645528793335),\n",
       " ('technical', 0.5530896782875061),\n",
       " ('deductive', 0.5486582517623901),\n",
       " ('artistry', 0.5484542846679688),\n",
       " ('vickerys', 0.5405755043029785)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('implementation', 0.5497423410415649),\n",
       " ('roadmap', 0.4897775948047638),\n",
       " ('calculated', 0.4576040208339691),\n",
       " ('actioni', 0.44992777705192566),\n",
       " ('hulka', 0.44863227009773254),\n",
       " ('therapuetic', 0.44706565141677856),\n",
       " ('conception', 0.44655200839042664),\n",
       " ('gingivitis', 0.44056543707847595),\n",
       " ('wholebody', 0.43626290559768677),\n",
       " ('dimeanor', 0.4339507818222046)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# his+(noun)-her\n",
    "model.wv.most_similar(positive=['his', 'execution'], negative=['her'], topn=10)\n",
    "# her+(noun)-his\n",
    "model.wv.most_similar(positive=['her', 'execution'], negative=['his'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cheerful', 0.5321331024169922),\n",
       " ('smiling', 0.5262094736099243),\n",
       " ('handshake', 0.5197967290878296),\n",
       " ('smiley', 0.493060439825058),\n",
       " ('cheery', 0.479512095451355),\n",
       " ('poise', 0.4728557765483856),\n",
       " ('smilei', 0.4726208746433258),\n",
       " ('smileand', 0.470217764377594),\n",
       " ('grin', 0.46686071157455444),\n",
       " ('welcome', 0.4646042287349701)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('hug', 0.5498396158218384),\n",
       " ('handshake', 0.51720130443573),\n",
       " ('pantie', 0.5140137672424316),\n",
       " ('scowl', 0.5068621635437012),\n",
       " ('grin', 0.48976388573646545),\n",
       " ('shoelace', 0.48190537095069885),\n",
       " ('girl', 0.47115427255630493),\n",
       " ('smirk', 0.46735459566116333),\n",
       " ('blanket', 0.4635048806667328),\n",
       " ('lollipop', 0.4630123972892761)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# his+(noun)-her\n",
    "model.wv.most_similar(positive=['his', 'smile'], negative=['her'], topn=10)\n",
    "# her+(noun)-his\n",
    "model.wv.most_similar(positive=['her', 'smile'], negative=['his'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lets', 0.4965308606624603),\n",
       " ('wink', 0.48335111141204834),\n",
       " ('bluntness', 0.47686275839805603),\n",
       " ('scowl', 0.46949297189712524),\n",
       " ('laughter', 0.46827754378318787),\n",
       " ('heas', 0.4680287837982178),\n",
       " ('smirk', 0.45693308115005493),\n",
       " ('smile', 0.45322272181510925),\n",
       " ('expression', 0.4438091516494751),\n",
       " ('poker', 0.4429737329483032)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('smirk', 0.6086892485618591),\n",
       " ('scowl', 0.60369873046875),\n",
       " ('pantie', 0.5709898471832275),\n",
       " ('she', 0.5605303645133972),\n",
       " ('screaming', 0.5567564368247986),\n",
       " ('tongue', 0.5254310965538025),\n",
       " ('zit', 0.5244307518005371),\n",
       " ('flashlight', 0.5176804661750793),\n",
       " ('blister', 0.5069534778594971),\n",
       " ('pant', 0.5042190551757812)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# his+(noun)-her\n",
    "model.wv.most_similar(positive=['his', 'grin'], negative=['her'], topn=10)\n",
    "# her+(noun)-his\n",
    "model.wv.most_similar(positive=['her', 'grin'], negative=['his'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('professional', 0.6197702288627625),\n",
       " ('charming', 0.6069566011428833),\n",
       " ('efficient', 0.6004388332366943),\n",
       " ('cordial', 0.5991696119308472),\n",
       " ('delightful', 0.5822018384933472),\n",
       " ('congenial', 0.582179069519043),\n",
       " ('cheerful', 0.5816338658332825),\n",
       " ('friendly', 0.5798388123512268),\n",
       " ('respectful', 0.5742918252944946),\n",
       " ('charismatic', 0.5739561915397644)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[('nurturing', 0.5317784547805786),\n",
       " ('sweet', 0.51926189661026),\n",
       " ('nurture', 0.5070083737373352),\n",
       " ('nonjudgemental', 0.4679553210735321),\n",
       " ('loving', 0.4642377495765686),\n",
       " ('cheery', 0.4581487774848938),\n",
       " ('bubbly', 0.4564359486103058),\n",
       " ('relatable', 0.4518079161643982),\n",
       " ('cheerful', 0.4480541944503784),\n",
       " ('warming', 0.4464818835258484)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# his+(noun)-her\n",
    "model.wv.most_similar(positive=['his', 'warm'], negative=['her'], topn=10)\n",
    "# her+(noun)-his\n",
    "model.wv.most_similar(positive=['her', 'warm'], negative=['his'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Method 2: vector similarities calculated by model\n",
    "- __Compute cosine similarity between two words__\n",
    "- E.g. Similarity('woman', 'man')=0.585, similarity('woman', 'woman')=1\n",
    "- similarity('she','professional') - similarity('he','professional') < 0  \n",
    "==>  male physicians are more likely to be associated with 'professional' in patients' comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20230704662320764\n",
      "-0.15150283317531602\n",
      "-0.05080421344789163\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('she','professional'))\n",
    "print(model.wv.similarity('he','professional'))\n",
    "\n",
    "print(model.wv.similarity('she','professional')-model.wv.similarity('he','professional'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05080421344789163\n",
      "0.0005303721403622508\n",
      "0.07739653979201196\n",
      "-------------\n",
      "0.04022910658313149\n",
      "0.01828594020133216\n",
      "0.006341864591320655\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('she','professional')-model.wv.similarity('he','professional'))\n",
    "print(model.wv.similarity('she','efficient')-model.wv.similarity('he','efficient'))\n",
    "print(model.wv.similarity('she','helpful')-model.wv.similarity('he','helpful'))\n",
    "print('-------------')\n",
    "print(model.wv.similarity('she','friendly')-model.wv.similarity('he','friendly'))\n",
    "print(model.wv.similarity('she','polite')-model.wv.similarity('he','polite'))\n",
    "print(model.wv.similarity('she','nice')-model.wv.similarity('he','nice'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.16854096134784646\n",
      "-0.1182542978886263\n",
      "-0.33514627863349655\n",
      "-------------\n",
      "0.04540064853195455\n",
      "0.015162475385465113\n",
      "0.03154003349371577\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('her','technique')-model.wv.similarity('his','technique'))\n",
    "print(model.wv.similarity('her','methodology')-model.wv.similarity('his','methodology'))\n",
    "print(model.wv.similarity('her','execution')-model.wv.similarity('his','execution'))\n",
    "print('-------------')\n",
    "print(model.wv.similarity('her','smile')-model.wv.similarity('his','smile'))\n",
    "print(model.wv.similarity('her','handshake')-model.wv.similarity('his','handshake'))\n",
    "print(model.wv.similarity('her','grin')-model.wv.similarity('his','grin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### By comparison, we found that female physicians are relatively more likely to be associate with comforting behaviors while male physicians are more frequently to be judged according to their professional standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Build sets of target words & attribute words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TW_adj_1= set(['technique','methodology','execution'])\n",
    "TW_adj_2= set(['friendly','polite','nice'])\n",
    "TW_n_1= set(['technique','methodology','methodology'])\n",
    "TW_n_2= set(['smile','handshake','grin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "AW_1= set(['she','her','female'])\n",
    "AW_2= set(['he','his','male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
